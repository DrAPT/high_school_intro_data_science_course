{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../predictioNN_Logo_JPG(72).jpg\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Logistic Regression with Breast Cancer Data\n",
    "\n",
    "### Introduction to Data Science\n",
    "#### Last Updated: February 24, 2023\n",
    "---  \n",
    "\n",
    "### SOURCES\n",
    "- [Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "### OBJECTIVES\n",
    "- Implement logistic regression using `sklearn`\n",
    "- Use the sigmoid function to compute the predicted probability\n",
    "- Compute binary classification metrics\n",
    "\n",
    "### CONCEPTS\n",
    "- logistic regression\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Logistic Regression with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We worked with the sigmoid function for computing probabilities of a binary outcome.  \n",
    "Logistic regression is a model that does these things:\n",
    "- Use a linear combination of predictors as input, equal to: $\\beta_0 + \\beta_1 X_1 + ... + \\beta_n X_n$\n",
    "- Feed the input into the sigmoid function (a.k.a. logistic function)\n",
    "- Estimate the parameters to minimize error\n",
    "- Output a probability estimate of the outcome\n",
    "\n",
    "Now we will work with the Wisconsin Breast Cancer Dataset to predict if a cell is benign ('B') or malignant ('M'). \n",
    "\n",
    "The dataset was sourced here:  \n",
    "https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../datasets/wdbc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis     f1     f2      f3      f4       f5       f6      f7  \\\n",
       "0    842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301         M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        f8  ...    f21    f22     f23     f24     f25     f26     f27     f28  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "      f29      f30  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the Fields**\n",
    "\n",
    "`id` - unique identifier for each subject  \n",
    "`diagnosis` - target variable indicating if cell is malignant or benign  \n",
    "`f1-f30` - cell measurement variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**\n",
    "\n",
    "The `diagnosis` field is the target variable. It needs to be converted to values of 0 and 1.  \n",
    "We can make malignant = 1, benign = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis     f1     f2      f3      f4       f5       f6      f7  \\\n",
      "0    842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
      "1    842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
      "2  84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
      "3  84348301         M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
      "4  84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
      "\n",
      "        f8  ...    f22     f23     f24     f25     f26     f27     f28  \\\n",
      "0  0.14710  ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
      "1  0.07017  ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
      "2  0.12790  ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
      "3  0.10520  ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
      "4  0.10430  ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
      "\n",
      "      f29      f30  target  \n",
      "0  0.4601  0.11890       1  \n",
      "1  0.2750  0.08902       1  \n",
      "2  0.3613  0.08758       1  \n",
      "3  0.6638  0.17300       1  \n",
      "4  0.2364  0.07678       1  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "         id diagnosis     f1     f2      f3      f4       f5       f6  \\\n",
      "564  926424         M  21.56  22.39  142.00  1479.0  0.11100  0.11590   \n",
      "565  926682         M  20.13  28.25  131.20  1261.0  0.09780  0.10340   \n",
      "566  926954         M  16.60  28.08  108.30   858.1  0.08455  0.10230   \n",
      "567  927241         M  20.60  29.33  140.10  1265.0  0.11780  0.27700   \n",
      "568   92751         B   7.76  24.54   47.92   181.0  0.05263  0.04362   \n",
      "\n",
      "          f7       f8  ...    f22     f23     f24      f25      f26     f27  \\\n",
      "564  0.24390  0.13890  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
      "565  0.14400  0.09791  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
      "566  0.09251  0.05302  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
      "567  0.35140  0.15200  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
      "568  0.00000  0.00000  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
      "\n",
      "        f28     f29      f30  target  \n",
      "564  0.2216  0.2060  0.07115       1  \n",
      "565  0.1628  0.2572  0.06637       1  \n",
      "566  0.1418  0.2218  0.07820       1  \n",
      "567  0.2650  0.4087  0.12400       1  \n",
      "568  0.0000  0.2871  0.07039       0  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the data, using f1 and f2 as predictors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['f1','f2']].values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into training set, test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, train_size = 0.6, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print some of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tr: \n",
      " [[19.21 18.57]\n",
      " [19.59 25.  ]\n",
      " [10.29 27.61]\n",
      " [13.85 19.6 ]\n",
      " [12.47 18.6 ]]\n",
      "\n",
      "y_tr: \n",
      " [1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('x_tr: \\n', x_tr[:5,:])\n",
    "print('')\n",
    "print('y_tr: \\n', y_tr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the logistic regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the model coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.08461051, 0.22651908]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the model intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.4275731])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the coefficient on f1 and f2 is 1.08461051 and 0.22651908, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict the Cell Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1\n",
      " 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 1 0 1 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# store the predictions for all subjects in a new column\n",
    "df['label_predicted'] = model.predict(X)\n",
    "\n",
    "# print the predictions\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter the dataframe to show subjects where the prediction matches the target. These are correct predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df['label_predicted'] == df['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict the Probability of Each Cell Type in Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00981234, 0.99018766],\n",
       "       [0.001527  , 0.998473  ],\n",
       "       [0.95314633, 0.04685367],\n",
       "       [0.72431022, 0.27568978],\n",
       "       [0.93638784, 0.06361216]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_tr)[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for the first subject, the probability of a benign cell is 0.00981234\n",
    "The probability of a malignant cell is 0.99018766\n",
    "\n",
    "Since the malignant probability is greater than the default threshold of 0.5, the predicted cell type is 1 (malignant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Positive Probabilities**\n",
    "\n",
    "It can be useful to extract the probabilities of the positive label for each subject.  \n",
    "This can be done by extracting the second index across all rows like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.90187665e-01, 9.98473003e-01, 4.68536694e-02, 2.75689785e-01,\n",
       "       6.36121602e-02, 6.64490382e-01, 6.08318342e-04, 9.98740086e-01,\n",
       "       3.00316027e-02, 2.22638228e-04, 1.95496262e-01, 9.69121999e-01,\n",
       "       9.97352442e-01, 7.23361530e-01, 1.82210018e-01, 9.61437814e-01,\n",
       "       9.15832160e-01, 9.99180405e-01, 5.27272025e-01, 6.82121502e-04,\n",
       "       4.00821485e-02, 2.70001375e-01, 4.18960044e-02, 9.92910823e-01,\n",
       "       4.26049965e-02, 9.72717081e-01, 9.95805052e-01, 2.53538062e-01,\n",
       "       9.99645994e-01, 9.87222697e-02, 9.99720529e-01, 6.97748324e-01,\n",
       "       4.46193904e-02, 9.72613518e-01, 2.76690213e-02, 1.61160956e-01,\n",
       "       1.26511261e-01, 3.89033693e-02, 5.84287849e-02, 3.72071168e-01,\n",
       "       6.79340036e-01, 5.88185506e-01, 1.03313627e-02, 2.46226871e-02,\n",
       "       9.85902604e-01, 9.51332119e-01, 9.99635763e-01, 7.16450651e-03,\n",
       "       7.69060702e-02, 1.71056600e-02, 2.60862252e-02, 9.77729619e-01,\n",
       "       1.04673106e-02, 7.39463454e-01, 8.94537086e-02, 8.10493161e-01,\n",
       "       9.97290044e-01, 1.32020403e-01, 8.76136476e-03, 7.10256432e-01,\n",
       "       9.97229767e-01, 8.68881462e-01, 7.68044761e-02, 2.63602238e-01,\n",
       "       9.91267976e-01, 4.42029090e-01, 2.35266415e-01, 9.00709661e-01,\n",
       "       4.45334277e-02, 4.19920059e-01, 5.33290709e-03, 9.65716626e-01,\n",
       "       9.97610003e-01, 9.92834372e-01, 1.99127306e-02, 7.72339396e-01,\n",
       "       3.89402438e-03, 1.45483620e-03, 3.67972522e-03, 2.36732936e-02,\n",
       "       2.53562334e-03, 9.99889231e-01, 2.09505633e-01, 9.98982643e-01,\n",
       "       1.52884932e-01, 9.82336065e-01, 3.44424937e-03, 8.84744326e-01,\n",
       "       7.09861201e-02, 9.77892230e-01, 2.23459139e-01, 8.30097746e-02,\n",
       "       4.24880228e-02, 7.61134978e-01, 4.87033195e-01, 3.20200079e-02,\n",
       "       8.78725359e-01, 1.09117425e-01, 1.74418599e-03, 6.12774005e-03,\n",
       "       1.93994618e-01, 2.76873722e-01, 1.25747474e-01, 2.50354148e-01,\n",
       "       9.77344892e-01, 9.99999349e-01, 6.96940598e-02, 4.09115755e-02,\n",
       "       6.84201923e-02, 1.78614734e-02, 9.99560956e-01, 6.24793286e-04,\n",
       "       1.17570018e-01, 9.98803346e-01, 1.87276106e-01, 4.34722461e-03,\n",
       "       2.04878357e-02, 2.19243090e-02, 3.72996107e-02, 4.05564003e-02,\n",
       "       9.99592393e-01, 1.79505528e-01, 8.67331075e-01, 1.13245901e-01,\n",
       "       8.78569592e-01, 6.35575574e-02, 2.09616659e-01, 8.07809331e-01,\n",
       "       3.33163625e-02, 5.57289385e-02, 7.88798941e-01, 3.65172469e-02,\n",
       "       5.72091878e-03, 9.98061063e-01, 1.75046614e-02, 9.18955476e-03,\n",
       "       5.87019180e-02, 9.88609306e-01, 4.81691211e-01, 9.98702930e-01,\n",
       "       6.23363095e-03, 2.03424505e-03, 9.99565893e-01, 1.81309468e-01,\n",
       "       4.98105663e-01, 1.83091715e-01, 9.98622850e-01, 2.12465750e-01,\n",
       "       6.08739050e-02, 7.66235350e-02, 3.90936825e-01, 2.17808480e-01,\n",
       "       5.70787125e-01, 6.34845200e-02, 1.13619235e-01, 1.26672193e-02,\n",
       "       1.48810991e-02, 2.84646892e-04, 9.77841985e-01, 5.12582223e-03,\n",
       "       9.77323633e-01, 4.18456182e-01, 7.12081965e-03, 9.81957480e-01,\n",
       "       1.95634710e-02, 7.80962213e-04, 1.14817192e-01, 7.16558239e-01,\n",
       "       1.82217284e-01, 3.21955021e-01, 9.97367195e-01, 1.81157851e-03,\n",
       "       5.65374595e-01, 4.61022245e-02, 9.74428431e-01, 8.71047244e-01,\n",
       "       4.79643411e-03, 9.83072868e-01, 9.31561604e-01, 5.61403115e-02,\n",
       "       7.75921318e-01, 9.62931145e-03, 6.45235733e-02, 4.84691362e-03,\n",
       "       2.42796404e-02, 1.38695858e-02, 9.99989184e-01, 2.03625987e-02,\n",
       "       6.76997421e-01, 3.54427654e-01, 8.05471417e-03, 2.65492561e-01,\n",
       "       9.97066132e-01, 2.90320115e-02, 1.72245958e-02, 9.93542797e-01,\n",
       "       2.36795278e-03, 5.11379123e-01, 8.53914302e-01, 2.09790857e-01,\n",
       "       1.22799308e-01, 6.14452427e-02, 2.53175973e-02, 6.02907492e-01,\n",
       "       7.56607946e-01, 1.61519664e-02, 8.83988019e-01, 1.22694490e-01,\n",
       "       9.69658437e-01, 1.76240103e-03, 1.50930275e-01, 3.46329689e-01,\n",
       "       2.22464961e-02, 9.01338916e-01, 1.65126285e-01, 9.37318521e-03,\n",
       "       2.00208765e-01, 1.66631504e-02, 9.39067333e-01, 8.29345988e-01,\n",
       "       9.97707824e-01, 7.04833275e-01, 9.87182455e-01, 9.43102836e-01,\n",
       "       9.98850178e-01, 3.51518247e-02, 1.14153287e-02, 4.06063843e-01,\n",
       "       9.73761773e-01, 6.15867519e-01, 2.96659865e-01, 6.65056201e-02,\n",
       "       9.53301232e-01, 1.21833733e-03, 7.68776318e-01, 9.98846004e-01,\n",
       "       9.89507264e-01, 9.83591450e-01, 4.33123124e-02, 6.89238742e-03,\n",
       "       2.70268677e-01, 9.55436456e-03, 6.98149496e-02, 3.05675837e-01,\n",
       "       1.57453850e-03, 2.44677517e-02, 3.83899892e-01, 9.80878162e-01,\n",
       "       3.30882509e-02, 4.02043640e-01, 1.84340394e-01, 6.98270442e-01,\n",
       "       9.99974306e-01, 9.98451365e-01, 9.99999209e-01, 4.23308247e-01,\n",
       "       2.55441705e-03, 8.73202040e-01, 8.90860040e-02, 7.86531718e-01,\n",
       "       5.91460673e-02, 9.75618946e-01, 2.40816236e-03, 5.57916256e-01,\n",
       "       9.04673115e-01, 1.88743539e-03, 2.89588826e-03, 2.51449570e-01,\n",
       "       5.46910463e-05, 5.34616185e-01, 3.40390327e-02, 6.40287340e-02,\n",
       "       4.62659718e-03, 5.25139906e-01, 2.01469418e-02, 3.70390812e-03,\n",
       "       6.11071027e-02, 8.08185800e-01, 3.04909622e-02, 6.91667764e-01,\n",
       "       2.03703023e-03, 8.23322119e-01, 2.62181489e-01, 1.39068741e-01,\n",
       "       3.57254328e-02, 9.99808266e-01, 9.98507531e-01, 3.00445889e-01,\n",
       "       5.69187233e-01, 1.79100055e-03, 9.92756237e-01, 1.12803794e-01,\n",
       "       1.17525456e-01, 3.15274307e-02, 1.47419930e-02, 3.75210581e-01,\n",
       "       2.30964788e-01, 4.82716731e-02, 9.97244893e-01, 4.42804778e-03,\n",
       "       9.99510169e-01, 4.98810039e-03, 2.49255072e-01, 5.13632172e-02,\n",
       "       9.73285984e-01, 9.85284804e-02, 2.16471002e-01, 9.99478910e-01,\n",
       "       1.05153695e-02, 9.07633646e-03, 9.86021666e-01, 9.99986039e-01,\n",
       "       2.97359817e-02, 9.99999765e-01, 1.43852215e-02, 3.44093584e-01,\n",
       "       7.92121319e-04, 9.99320529e-01, 7.39744224e-02, 2.74994091e-02,\n",
       "       1.56004158e-02, 1.71844281e-01, 6.41261178e-03, 3.49513470e-02,\n",
       "       3.04056972e-02, 8.25751720e-02, 7.18694642e-01, 9.99888979e-01,\n",
       "       1.16458199e-01, 6.19380302e-03, 8.01940157e-01, 9.92056750e-01,\n",
       "       7.09537073e-01, 3.70163187e-02, 5.68855258e-04, 1.29554451e-01,\n",
       "       3.67597417e-03, 5.64699057e-02, 7.86602812e-01, 9.97201552e-01,\n",
       "       7.47892482e-04])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_tr)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to change the threshold, predicting cell type 1 if the probability of the positive label is greater than 0.85. This now requires a higher confidence compared to using 0.5 as the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False, False,  True, False,\n",
       "       False, False,  True,  True, False, False,  True,  True,  True,\n",
       "       False, False, False, False, False,  True, False,  True,  True,\n",
       "       False,  True, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False,  True,  True, False,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False,  True, False,  True, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False,  True, False,  True, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "       False,  True, False, False,  True,  True, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_tr)[:,1] > 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measuring Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141,  10],\n",
       "       [ 19,  58]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_te, model.predict(x_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute batch of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       151\n",
      "           1       0.85      0.75      0.80        77\n",
      "\n",
      "    accuracy                           0.87       228\n",
      "   macro avg       0.87      0.84      0.85       228\n",
      "weighted avg       0.87      0.87      0.87       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_te, model.predict(x_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute metrics over range of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.87692308 0.890625   0.9047619  0.90322581 0.90163934]\n",
      "\n",
      "recall:    [0.74025974 0.74025974 0.74025974 0.72727273 0.71428571]\n",
      "\n",
      "threshold: [0.52326871 0.53113831 0.53937435 0.55367587 0.563716  ]\n"
     ]
    }
   ],
   "source": [
    "# probabilities of positive class from test set\n",
    "pred_pos = model.predict_proba(x_te)[:,1]\n",
    "\n",
    "# calculate metrics over range of thresholds\n",
    "pre, re, th = precision_recall_curve(y_te,  pred_pos)\n",
    "\n",
    "# print metrics for a sample of thresholds\n",
    "print('precision:', pre[100:105])\n",
    "print('')\n",
    "print('recall:   ', re[100:105])\n",
    "print('')\n",
    "print('threshold:', th[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that as threshold increases:\n",
    "- precision increases (fewer false positives)\n",
    "- recall decreases (more false negatives)\n",
    "\n",
    "This is the tradeoff in classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**THINK ABOUT AND DISCUSS**\n",
    "\n",
    "1) If you raise the threshold for predicting a positive label, what generally happens to the recall? What generally happens to the precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "answer: Since we require a higher confidence to predict the positive label, the precision will likely increase.  However, the recall will likely decrease, producing more false negatives. This is why it is important to measure precision and recall together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TRY FOR YOURSELF**\n",
    "\n",
    "You will evaluate the model performance.\n",
    "\n",
    "Hint: you can count the number of rows in a dataframe by using the `len()` function like this: `len(df)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute the accuracy of the model, where accuracy = #correct / #total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "len(df[df['label_predicted'] == df['target']]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Count the number of true positives (where the model predicted 1 and the target is 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "len(df[ (df['label_predicted'] == 1) & (df['target'] == 1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Compute the recall of the model, where precision = #true_positive / #actual_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "len(df[ (df['label_predicted'] == 1) & (df['target'] == 1) ]) / len( df[df['target'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) As we saw earlier, the first subject in the training set has a probability of malignancy = 0.99018766  \n",
    "Compute this by using the intercept, coefficients, f1, f2 values, and the definition of the sigmoid:\n",
    "\n",
    "$sigmoid = 1 / ( 1 + np.exp(-(b0 + b1 * x1 + b2 * x2) ))$\n",
    "\n",
    "Note this version uses two predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99018766])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#answer\n",
    "b0 = model.intercept_\n",
    "b1 = model.coef_[0][0]\n",
    "b2 = model.coef_[0][1]\n",
    "x1 = x_tr[0][0]\n",
    "x2 = x_tr[0][1]\n",
    "\n",
    "1 / ( 1 + np.exp(-(b0 + b1 * x1 + b2 * x2) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
