{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Modeling and an Introduction to sklearn\n",
    "### Introduction to Data Science\n",
    "### Last Updated: November 19, 2022\n",
    "---  \n",
    "\n",
    "### PREREQUISITES\n",
    "- variables\n",
    "- data types\n",
    "- pandas\n",
    "\n",
    "### SOURCES \n",
    "- [sklearn Introduction](https://scikit-learn.org/stable/index.html)\n",
    "- [R-Squared in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)\n",
    "\n",
    "### OBJECTIVES\n",
    "- Identify variables that should not be used as predictors as they would introduce bias into the model\n",
    "- Understand why a model is trained on a portion of the data\n",
    "- Introduce some basic functionality of the `sklearn` package\n",
    "- Illustrate how to fit a linear regression model with `sklearn`\n",
    "- Compare the fit of two linear regression models using their fit statistics\n",
    "\n",
    "### CONCEPTS\n",
    "- `sklearn` interface\n",
    "- predictors that can introduce bias or ethical issues should not be used in models\n",
    "- splitting data into training set and testing set\n",
    "- generalization of patterns to new data\n",
    "- target variable and predictor variables\n",
    "- making predictions from a model\n",
    "- assessing model fit with R-squared\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Motivating Model Fitting\n",
    "\n",
    "We now have cleaned, prepared data in a format ready for modeling.  \n",
    "We learned how to transform data into useful features.  \n",
    "Here, we discuss fitting a model to the data.  \n",
    "Typical reasons for modeling:\n",
    "- understanding how the features **explain** the target\n",
    "- using the features to **predict** the target\n",
    "\n",
    "Model fitting is done with software packages.  \n",
    "We discuss a powerful Python package for machine learning: `scikit-learn` (`sklearn` for short).  \n",
    "\n",
    "This notebook will provides an outline of *linear regression* and a very brief demo of `sklearn`. You are encouraged to explore and go further.\n",
    "\n",
    "**NOTE:**  \n",
    "Be sure to confirm the validity of the data before training a model on it.  \n",
    "Describing the data with statistical summaries will be helpful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Introducing Linear Regression\n",
    "\n",
    "The simplest model form is linear regression, which assumes a linear relationship between one or more predictors $X$ and expected value of the target $Y$. \n",
    "\n",
    "We won't discuss all of the Gauss Markov assumptions of linear regression (but a good book on the subject will cover it).\n",
    "\n",
    "The mathematical form is:\n",
    "\n",
    "$E(Y) = \\beta_0 + \\beta_1 X_1 + ... + \\beta_n X_n$\n",
    "\n",
    "where \n",
    "\n",
    "- $E(Y)$ is the target\n",
    "- $\\beta_0$ is an intercept parameter\n",
    "- $\\beta_1$, ..., $\\beta_n$ are slope parameters or *weights*\n",
    "- $X_1$, ..., $X_n$ are predictors\n",
    "- $n$ is the number of predictors, which is one in the simplest case\n",
    "\n",
    "When all predictors are zero, the target value is equal to $\\beta_0$\n",
    "\n",
    "For the case of a single predictor, the model is called *simple linear regression*.\n",
    "\n",
    "**The key to regression is to discover the best set of predictors that explains or predicts the target.**  \n",
    "As we add useful predictors, it is possible to minimize the error between the predicted values and the target values.\n",
    "\n",
    "Additionally, the intercept and weights are estimated from data (model fitting).  \n",
    "These parameter values are determined such that the errors between the predicted values and the target values are minimized.  \n",
    "\n",
    "\n",
    "We turn to model fitting with sklearn next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Being Thoughtful About Features\n",
    "\n",
    "It may be tempting, particularly in the age of automation, to include all features in the model, perhaps letting the algorithm arrive at the best set.\n",
    "\n",
    "There are some important things to think about when deciding features:\n",
    "\n",
    "1. The features should make intuitive sense. In practice, the data scientist might discuss the features with the line of business, the product manager, and other stakeholders.\n",
    "\n",
    "2. **The features should not introduce bias into the model, or introduce ethical issues.**\n",
    "\n",
    "One needs to be careful around the use of demographic variables, as it can be easy to discriminate based on age, gender, race, and ethnicity.\n",
    "\n",
    "Examples of variables that would introduce bias, and therefore should be avoided in modeling, include:\n",
    "\n",
    "- age, race, ethnicity, gender, religion, disability, color, national origin, religion\n",
    "- employment type, where some jobs are skewed toward one gender, such as nursing (this targets females)\n",
    "- an indicator if a person pressed 2 to hear a message in Spanish (this targets an ethnicity)\n",
    "- salary (this targets race/ethnicity)\n",
    "- the kind of cuisine served at a restaurant (this is more subtle, but can target race/ethnicity)\n",
    "\n",
    "For the *salary* predictor, if one were predicting who might default on a mortgage, it would be better from an ethics viewpoint to use *debt/income* as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**THINK ABOUT AND DISCUSS**\n",
    "\n",
    "Can you think of other predictors that could introduce bias in a model?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the model predictors should be carefully considered. It is not enough that predictors improve the model fit; they must also make sense and not cause harm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Fit a Regression Model\n",
    "\n",
    "### A. Fetch and Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sklearn dataset and functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score # R-squared\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fetch a built-in housing price dataset from `sklearn`.  \n",
    "The data is based on a California district and it is aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect what's in the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is also called the `response variable`, `outcome variable`, or `dependent variable`.  \n",
    "Different subject areas give it a different name. In machine learning, `target` is used.\n",
    "\n",
    "**The targets represent scaled house prices (they are divided by 100,000)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*housing.data* contains the data in an array object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the shape of the array: (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, look at the feature names. Features are also called `factors`, `predictors`, or `independent variables`.  \n",
    "Again, this depends on the subject area. In machine learning, `feature` or `predictor` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These features may be useful in predicting house prices (the targets).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Data Splitting\n",
    "\n",
    "When we train a model on a dataset, it learns the patterns in that data.    \n",
    "In fact, it might learn it too well, memorizing nuances (overfitting).  \n",
    "There is a very real risk that the model might not do well on new data it hasn't seen.\n",
    "\n",
    "To help reduce this risk, we do this:  \n",
    "1. Split the data into several pieces. Here, we use two pieces called a **train set** and a **test set**.  \n",
    "2. Train the model on the train set  \n",
    "3. Evaluate the model on the test set\n",
    "\n",
    "The hope is that the model learns the right patterns, and that it **generalizes** to the test set.  \n",
    "This means that the model performs similarly on the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 60% train, 40% test sets. The helper function `train_test_split` can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(housing.data, housing.target, train_size = 0.6, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: what is the data type holding these numbers?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will scale the data by following these steps:\n",
    "\n",
    "1. Scale the x_train and x_test data using `StandardScaler`. **Why do we do this?**\n",
    "2. Train a regression model on (x_train, y_train). **This is common notation to show that X and Y are paired into observations used in training the model**\n",
    "3. Feed `x_test` into the model to make predictions `y_test_predicted`\n",
    "4. Evaluate model performance by comparing `y_test_predicted` to `y_test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Instantiate StandardScaler object and fit it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How this works: the scaler does three things:\n",
    "1. it computes the means and standard deviations of each column and saves them\n",
    "2. for each column, it subtracts its mean\n",
    "2. for each column, it divides by its standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the scaled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column means are roughly all zero. This shows they are centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column standard deviations are all one. This shows they are scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### D. Set up and Fit Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"linreg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the passed data matters: (x, y)\n",
    "\n",
    "Remember to used the scaled X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the predictor coefficients (also called `weights` or `betas`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the `intercept`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Predictions on test set (use *x_test_s* to predict *y_test*).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you'll want to scale the `x_test` data.  \n",
    "**Important point**: reuse the scaler from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_s = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, feed `x_test_s` into the model to predict `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = reg.predict(x_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Evaluate Model Performance\n",
    "\n",
    "Notice: since we know `y_test`, we can compare it to our predictions.  \n",
    "\n",
    "A common model fit metric for linear regression is `R-squared`.  \n",
    "\n",
    "It measures the fraction of variation in Y explained by the model. A higher value is better.\n",
    "\n",
    "The value's range is $[0,1]$ where zero means no explanatory power, and one means perfect explanatory power.\n",
    "\n",
    "If you are interested in the details of the calculation, see the **Appendix** below.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute R-squared by calling the function: `r2_score`  \n",
    "Note that the order of the inputs matters: (true, predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model explains more than half of the variation in prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a model using **only the first three predictors**, and measure the R-squared for comparison.  \n",
    "It probably won't be as high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_subset = x_train[:,:3] # use all rows, and first three columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new scaling object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "x_train_subset_s = scaler2.fit_transform(x_train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = LinearRegression().fit(x_train_subset_s, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform the first three predictors in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_subset_s = scaler2.fit_transform(x_test[:,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted2 = reg2.predict(x_test_subset_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test, y_test_predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we expected, it doesn't do as well: 0.521 versus 0.608 from the larger model.  \n",
    "This tells us that the predictors we dropped were important in explaining the target.\n",
    "\n",
    "**Ultimately, R-squared is a useful way to compare the predictive power to two models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRY FOR YOURSELF\n",
    "\n",
    "1. Repeat the process on your own dataset:\n",
    "   - Use `sklearn` to split the data, select predictors, scale them, fit a model, predict the targets in the test set, and compute R-squared\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select a different set of predictors and repeat the process from (1). What do the results tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Calculating R-Squared with a Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`R-squared` is easily calculated in software, but the formula is:\n",
    "\n",
    "$$R-squared = 1 - SS_{res} / SS_{tot}$$\n",
    "\n",
    "where\n",
    "\n",
    "`SS_res` is the sum of squared residuals. This is computed by:\n",
    "1. calculating the residuals: `y_test - y_test_predicted` for each data point. these are errors, where smaller is better.\n",
    "2. squaring the residuals\n",
    "3. summing the squared residuals\n",
    "\n",
    "`SS_tot` is the total sum of squares. This is computed by:\n",
    "1. Computing the average of `y_test`, which we call `y_test_mean`\n",
    "2. calculating the residuals: `y_test - y_test_mean` for each data point.\n",
    "3. squaring the residuals\n",
    "4. summing the squared residuals\n",
    "\n",
    "Conceptually, there is generally variance in the data, and `SS_tot` is proportional to that variance.  \n",
    "if `SS_{res}` is much smaller than `SS_tot`, it says that the model is explaining most of that variance.  \n",
    "This results in `R-squared` close to one.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
